{
    "docs": [
        {
            "location": "/", 
            "text": "GenomicFeatures.jl\n\n\n\n\nDescription\n\n\nGenomicFeatures.jl provides genomic interval arithmetic, data structures, and I/O tools for various data formats including BED, GFF3, bigWig, and bigBed.\n\n\n\n\nInstallation\n\n\nInstall GenomicFeatures from the Julia REPL:\n\n\njulia\n \nPkg\n.\nadd\n(\nGenomicFeatures\n)\n\n\n\n\n\n\nIf you are interested in the cutting edge of the development, please check out the master branch to try new features before release.", 
            "title": "Home"
        }, 
        {
            "location": "/#genomicfeaturesjl", 
            "text": "", 
            "title": "GenomicFeatures.jl"
        }, 
        {
            "location": "/#description", 
            "text": "GenomicFeatures.jl provides genomic interval arithmetic, data structures, and I/O tools for various data formats including BED, GFF3, bigWig, and bigBed.", 
            "title": "Description"
        }, 
        {
            "location": "/#installation", 
            "text": "Install GenomicFeatures from the Julia REPL:  julia   Pkg . add ( GenomicFeatures )   If you are interested in the cutting edge of the development, please check out the master branch to try new features before release.", 
            "title": "Installation"
        }, 
        {
            "location": "/intervals/", 
            "text": "Genomic Interval Manipulation\n\n\nThe \nGenomicFeatures\n module consists of tools for working efficiently with genomic intervals.\n\n\n\n\nInterval type\n\n\nIntervals in GenomicFeatures.jl are consistent with ranges in Julia: \n1-based and end-inclusive\n. When data is read from formats with different representations (i.e. 0-based and/or end-exclusive) they are always converted automatically.  Similarly when writing data. You should not have to reason about off-by-one errors due to format differences while using functionality provided in GenomicFeatures.jl.\n\n\nThe \nInterval\n type is defined as\n\n\nimmutable\n \nInterval\n{\nT\n}\n \n:\n \nAbstractInterval\n{\nInt64\n}\n\n    \nseqname\n::\nString\n\n    \nfirst\n::\nInt64\n\n    \nlast\n::\nInt64\n\n    \nstrand\n::\nStrand\n\n    \nmetadata\n::\nT\n\n\nend\n\n\n\n\n\n\nThe first three fields (\nseqname\n, \nfirst\n, and \nlast\n) are mandatory arguments when constructing an \nInterval\n object. \nseqname\n is the sequence name associated with the interval. The \nfirst\n and \nlast\n fields are the leftmost and rightmost positions of the interval, which can be accessed with \nleftposition\n and \nrightposition\n functions, respectively.\n\n\nThe \nstrand\n field can take four kinds of values listed in the next table:\n\n\n\n\n\n\n\n\nSymbol\n\n\nConstant\n\n\nMeaning\n\n\n\n\n\n\n\n\n\n\n'?'\n\n\nSTRAND_NA\n\n\nstrand is unknown or inapplicable\n\n\n\n\n\n\n'+'\n\n\nSTRAND_POS\n\n\npositive strand\n\n\n\n\n\n\n'-'\n\n\nSTRAND_NEG\n\n\nnegative strand\n\n\n\n\n\n\n'.'\n\n\nSTRAND_BOTH\n\n\nnon-strand-specific feature\n\n\n\n\n\n\n\n\nInterval\n is parameterized on metadata type, which lets it efficiently and precisely be specialized to represent intervals from a variety of formats.\n\n\nThe default strand and metadata value are \nSTRAND_BOTH\n and \nnothing\n:\n\n\njulia\n \nInterval\n(\nchr1\n,\n \n10000\n,\n \n20000\n)\n\n\nGenomicFeatures.Interval{Void}:\n\n\n  sequence name: chr1\n\n\n  leftmost position: 10000\n\n\n  rightmost position: 20000\n\n\n  strand: .\n\n\n  metadata: nothing\n\n\n\njulia\n \nInterval\n(\nchr1\n,\n \n10000\n,\n \n20000\n,\n \n+\n)\n\n\nGenomicFeatures.Interval{Void}:\n\n\n  sequence name: chr1\n\n\n  leftmost position: 10000\n\n\n  rightmost position: 20000\n\n\n  strand: +\n\n\n  metadata: nothing\n\n\n\n\n\n\nThe following example shows all accessor functions for the five fields:\n\n\njulia\n \ni\n \n=\n \nInterval\n(\nchr1\n,\n \n10000\n,\n \n20000\n,\n \n+\n,\n \nsome annotation\n)\n\n\nGenomicFeatures.Interval{String}:\n\n\n  sequence name: chr1\n\n\n  leftmost position: 10000\n\n\n  rightmost position: 20000\n\n\n  strand: +\n\n\n  metadata: some annotation\n\n\n\njulia\n \nseqname\n(\ni\n)\n\n\nchr1\n\n\n\njulia\n \nleftposition\n(\ni\n)\n\n\n10000\n\n\n\njulia\n \nrightposition\n(\ni\n)\n\n\n20000\n\n\n\njulia\n \nstrand\n(\ni\n)\n\n\nSTRAND_POS\n\n\n\njulia\n \nmetadata\n(\ni\n)\n\n\nsome annotation\n\n\n\n\n\n\n\n\nCollections of intervals\n\n\nCollections of intervals are represented using the \nIntervalCollection\n type, which is a general purpose indexed container for intervals. It supports fast intersection operations as well as insertion, deletion, and sorted iteration.\n\n\nInterval collections can be initialized by inserting elements one by one using \npush!\n.\n\n\n# The type parameter (Void here) indicates the interval metadata type.\n\n\ncol\n \n=\n \nIntervalCollection\n{\nVoid\n}()\n\n\n\nfor\n \ni\n \nin\n \n1\n:\n100\n:\n10000\n\n    \npush!\n(\ncol\n,\n \nInterval\n(\nchr1\n,\n \ni\n,\n \ni\n \n+\n \n99\n))\n\n\nend\n\n\n\n\n\n\nIncrementally building an interval collection like this works, but \nIntervalCollection\n also has a bulk insertion constructor that is able to build the indexed data structure extremely efficiently from an array of intervals.\n\n\ncol\n \n=\n \nIntervalCollection\n([\nInterval\n(\nchr1\n,\n \ni\n,\n \ni\n \n+\n \n99\n)\n \nfor\n \ni\n \nin\n \n1\n:\n100\n:\n10000\n])\n\n\n\n\n\n\nBulding \nIntervalCollections\n in one shot like this should be preferred when it's convenient or speed in an issue.\n\n\nIntervalCollection\ns can also be build directly from a genome annotation file, here in GFF3 format:\n\n\nreader\n \n=\n \nopen\n(\nGFF3\n.\nReader\n,\n \nsome_genome.gff3\n)\n\n\nfeatures\n \n=\n \nIntervalCollection\n(\nreader\n)\n\n\n\n\n\n\n\n\nOverlap query\n\n\nThere are number of \neachoverlap\n function in the \nGenomicFeatures\n module. They follow two patterns: interval versus collection queries which return an iterator over intervals in the collection that overlap the query, and collection versus collection queries which iterate over all pairs of overlapping intervals.\n\n\n#\n\n\nGenomicFeatures.eachoverlap\n \n \nFunction\n.\n\n\neachoverlap(intervals_a, intervals_b, [seqname_isless=Base.isless])\n\n\n\n\n\nCreate an iterator of overlapping intervals between \nintervals_a\n and \nintervals_b\n.\n\n\nThis function assumes elements of \nintervals_a\n and \nintervals_b\n are sorted by its sequence name and left position.  If the element type is not a subtype of \nGenomicFeatures.Interval\n, elements are converted to \nInterval\n objects.\n\n\nThe third optional argument is a function that defines the order of sequence names. The default function is \nBase.isless\n, which is the lexicographical order.\n\n\nsource\n\n\nThe order of interval pairs is the same as the following nested loop but \neachoverlap\n is often much faster:\n\n\nfor\n \na\n \nin\n \nintervals_a\n,\n \nb\n \nin\n \nintervals_b\n\n    \nif\n \nisoverlapping\n(\na\n,\n \nb\n)\n\n        \n# do something...\n\n    \nend\n\n\nend\n\n\n\n\n\n\n\n\nInterval streams\n\n\nIntervals need not necessarily stored in an indexed data structure for efficient intersection to be practical. Two collections of intervals need only be both sorted to compute all overlapping pairs. This is particularly useful in genomics where datasets are sometimes so large that loading them entirely into memory is not practical.\n\n\nThe \nGenomicFeatures\n module is able to intersect any two iterators that yield intervals in sorted order, which we refer to as \"interval streams\". An \nIntervalCollection\n is also an interval stream, but so is a sorted array of intervals, and parsers over interval file formats. This allows for a very general notion of intersection.\n\n\nfeatures_x\n \n=\n \nopen\n(\nBED\n.\nReader\n,\n \nfeatures_x.bed\n)\n\n\nfeatures_y\n \n=\n \nopen\n(\nBED\n.\nReader\n,\n \nfeatures_y.bed\n)\n\n\nfor\n \n(\nx\n,\n \ny\n)\n \nin\n \neachoverlap\n(\nfeatures_x\n,\n \nfeatures_y\n)\n\n    \nprintln\n(\nintersection found between \n,\n \nx\n,\n \n and \n,\n \ny\n)\n\n\nend\n\n\nclose\n(\nfeatures_x\n)\n\n\nclose\n(\nfeatures_y\n)\n\n\n\n\n\n\nAn exception will be thrown if an interval in encountered out of order while processing an interval stream. Ordering of intervals has one complication: there is not necessarily a standardized way to order sequence names. By default in GenomicFeatures.jl intervals are sorted using a \nBase.isless\n comparison function that is a default order in most command-line tools.\n\n\nA special sort of intersection can also be performed on an interval stream against itself to produce \"coverage intervals\".\n\n\n#\n\n\nGenomicFeatures.coverage\n \n \nFunction\n.\n\n\ncoverage(intervals)\n\n\n\n\n\nCompute the coverage of a collection of intervals and return an \nIntervalCollection\n that contains run-length encoded coverage data.\n\n\nFor example, given intervals like:\n\n\n[------]     [------------]\n\n   \n[---------------]\n\n\n\n\n\n\nThis function would return a new set of disjoint intervals with annotated coverage like:\n\n\n[1][-2-][-1-][--2--][--1--]\n\n\n\n\n\nsource", 
            "title": "Intervals"
        }, 
        {
            "location": "/intervals/#genomic-interval-manipulation", 
            "text": "The  GenomicFeatures  module consists of tools for working efficiently with genomic intervals.", 
            "title": "Genomic Interval Manipulation"
        }, 
        {
            "location": "/intervals/#interval-type", 
            "text": "Intervals in GenomicFeatures.jl are consistent with ranges in Julia:  1-based and end-inclusive . When data is read from formats with different representations (i.e. 0-based and/or end-exclusive) they are always converted automatically.  Similarly when writing data. You should not have to reason about off-by-one errors due to format differences while using functionality provided in GenomicFeatures.jl.  The  Interval  type is defined as  immutable   Interval { T }   :   AbstractInterval { Int64 } \n     seqname :: String \n     first :: Int64 \n     last :: Int64 \n     strand :: Strand \n     metadata :: T  end   The first three fields ( seqname ,  first , and  last ) are mandatory arguments when constructing an  Interval  object.  seqname  is the sequence name associated with the interval. The  first  and  last  fields are the leftmost and rightmost positions of the interval, which can be accessed with  leftposition  and  rightposition  functions, respectively.  The  strand  field can take four kinds of values listed in the next table:     Symbol  Constant  Meaning      '?'  STRAND_NA  strand is unknown or inapplicable    '+'  STRAND_POS  positive strand    '-'  STRAND_NEG  negative strand    '.'  STRAND_BOTH  non-strand-specific feature     Interval  is parameterized on metadata type, which lets it efficiently and precisely be specialized to represent intervals from a variety of formats.  The default strand and metadata value are  STRAND_BOTH  and  nothing :  julia   Interval ( chr1 ,   10000 ,   20000 )  GenomicFeatures.Interval{Void}:    sequence name: chr1    leftmost position: 10000    rightmost position: 20000    strand: .    metadata: nothing  julia   Interval ( chr1 ,   10000 ,   20000 ,   + )  GenomicFeatures.Interval{Void}:    sequence name: chr1    leftmost position: 10000    rightmost position: 20000    strand: +    metadata: nothing   The following example shows all accessor functions for the five fields:  julia   i   =   Interval ( chr1 ,   10000 ,   20000 ,   + ,   some annotation )  GenomicFeatures.Interval{String}:    sequence name: chr1    leftmost position: 10000    rightmost position: 20000    strand: +    metadata: some annotation  julia   seqname ( i )  chr1  julia   leftposition ( i )  10000  julia   rightposition ( i )  20000  julia   strand ( i )  STRAND_POS  julia   metadata ( i )  some annotation", 
            "title": "Interval type"
        }, 
        {
            "location": "/intervals/#collections-of-intervals", 
            "text": "Collections of intervals are represented using the  IntervalCollection  type, which is a general purpose indexed container for intervals. It supports fast intersection operations as well as insertion, deletion, and sorted iteration.  Interval collections can be initialized by inserting elements one by one using  push! .  # The type parameter (Void here) indicates the interval metadata type.  col   =   IntervalCollection { Void }()  for   i   in   1 : 100 : 10000 \n     push! ( col ,   Interval ( chr1 ,   i ,   i   +   99 ))  end   Incrementally building an interval collection like this works, but  IntervalCollection  also has a bulk insertion constructor that is able to build the indexed data structure extremely efficiently from an array of intervals.  col   =   IntervalCollection ([ Interval ( chr1 ,   i ,   i   +   99 )   for   i   in   1 : 100 : 10000 ])   Bulding  IntervalCollections  in one shot like this should be preferred when it's convenient or speed in an issue.  IntervalCollection s can also be build directly from a genome annotation file, here in GFF3 format:  reader   =   open ( GFF3 . Reader ,   some_genome.gff3 )  features   =   IntervalCollection ( reader )", 
            "title": "Collections of intervals"
        }, 
        {
            "location": "/intervals/#overlap-query", 
            "text": "There are number of  eachoverlap  function in the  GenomicFeatures  module. They follow two patterns: interval versus collection queries which return an iterator over intervals in the collection that overlap the query, and collection versus collection queries which iterate over all pairs of overlapping intervals.  #  GenomicFeatures.eachoverlap     Function .  eachoverlap(intervals_a, intervals_b, [seqname_isless=Base.isless])  Create an iterator of overlapping intervals between  intervals_a  and  intervals_b .  This function assumes elements of  intervals_a  and  intervals_b  are sorted by its sequence name and left position.  If the element type is not a subtype of  GenomicFeatures.Interval , elements are converted to  Interval  objects.  The third optional argument is a function that defines the order of sequence names. The default function is  Base.isless , which is the lexicographical order.  source  The order of interval pairs is the same as the following nested loop but  eachoverlap  is often much faster:  for   a   in   intervals_a ,   b   in   intervals_b \n     if   isoverlapping ( a ,   b ) \n         # do something... \n     end  end", 
            "title": "Overlap query"
        }, 
        {
            "location": "/intervals/#interval-streams", 
            "text": "Intervals need not necessarily stored in an indexed data structure for efficient intersection to be practical. Two collections of intervals need only be both sorted to compute all overlapping pairs. This is particularly useful in genomics where datasets are sometimes so large that loading them entirely into memory is not practical.  The  GenomicFeatures  module is able to intersect any two iterators that yield intervals in sorted order, which we refer to as \"interval streams\". An  IntervalCollection  is also an interval stream, but so is a sorted array of intervals, and parsers over interval file formats. This allows for a very general notion of intersection.  features_x   =   open ( BED . Reader ,   features_x.bed )  features_y   =   open ( BED . Reader ,   features_y.bed )  for   ( x ,   y )   in   eachoverlap ( features_x ,   features_y ) \n     println ( intersection found between  ,   x ,    and  ,   y )  end  close ( features_x )  close ( features_y )   An exception will be thrown if an interval in encountered out of order while processing an interval stream. Ordering of intervals has one complication: there is not necessarily a standardized way to order sequence names. By default in GenomicFeatures.jl intervals are sorted using a  Base.isless  comparison function that is a default order in most command-line tools.  A special sort of intersection can also be performed on an interval stream against itself to produce \"coverage intervals\".  #  GenomicFeatures.coverage     Function .  coverage(intervals)  Compute the coverage of a collection of intervals and return an  IntervalCollection  that contains run-length encoded coverage data.  For example, given intervals like:  [------]     [------------] \n    [---------------]   This function would return a new set of disjoint intervals with annotated coverage like:  [1][-2-][-1-][--2--][--1--]  source", 
            "title": "Interval streams"
        }, 
        {
            "location": "/io/bed/", 
            "text": "BED\n\n\n\n\nDescription\n\n\nBED is a text-based file format for representing genomic annotations like genes, transcripts, and so on. A BED file has tab-delimited and variable-length fields; the first three fields denoting a genomic interval are mandatory.\n\n\nThis is an example of RNA transcripts:\n\n\nchr9    68331023    68424451    NM_015110   0   +\nchr9    68456943    68486659    NM_001206   0   -\n\n\n\n\n\nI/O tools for BED are provided from the \nGenomicFeatures.BED\n module, which exports following three types:\n\n\n\n\nReader type: \nBED.Reader\n\n\nWriter type: \nBED.Writer\n\n\nElement type: \nBED.Record\n\n\n\n\n\n\nExamples\n\n\nHere is a common workflow to iterate over all records in a BED file:\n\n\n# Import the BED module.\n\n\nusing\n \nGenomicFeatures\n\n\n\n# Open a BED file.\n\n\nreader\n \n=\n \nopen\n(\nBED\n.\nReader\n,\n \ndata.bed\n)\n\n\n\n# Iterate over records.\n\n\nfor\n \nrecord\n \nin\n \nreader\n\n    \n# Do something on record (see Accessors section).\n\n    \nchrom\n \n=\n \nBED\n.\nchrom\n(\nrecord\n)\n\n    \n# ...\n\n\nend\n\n\n\n# Finally, close the reader.\n\n\nclose\n(\nreader\n)\n\n\n\n\n\n\nIf you repeatedly access records within specific ranges, it would be more efficient to construct an \nIntervalCollection\n object from a BED reader:\n\n\n# Create an interval collection in memory.\n\n\nicol\n \n=\n \nopen\n(\nBED\n.\nReader\n,\n \ndata.bed\n)\n \ndo\n \nreader\n\n    \nIntervalCollection\n(\nreader\n)\n\n\nend\n\n\n\n# Query overlapping records.\n\n\nfor\n \ninterval\n \nin\n \neachoverlap\n(\nicol\n,\n \nInterval\n(\nchrX\n,\n \n40001\n,\n \n51500\n))\n\n    \n# A record is stored in the metadata field of an interval.\n\n    \nrecord\n \n=\n \nmetadata\n(\ninterval\n)\n\n    \n# ...\n\n\nend\n\n\n\n\n\n\n\n\nAPI\n\n\n#\n\n\nGenomicFeatures.BED.Reader\n \n \nType\n.\n\n\nBED\n.\nReader\n(\ninput\n::\nIO\n;\n \nindex\n=\nnothing\n)\n\n\nBED\n.\nReader\n(\ninput\n::\nAbstractString\n;\n \nindex\n=\n:\nauto\n)\n\n\n\n\n\n\nCreate a data reader of the BED file format.\n\n\nThe first argument specifies the data source. When it is a filepath that ends with \n.bgz\n, it is considered to be block compression file format (BGZF) and the function will try to find a tabix index file (\n.tbi) and read it if any. See \nhttp://www.htslib.org/doc/tabix.html\n for bgzip and tabix tools.\n\n\nArguments\n\n\n\n\ninput\n: data source\n\n\nindex\n: path to a tabix file\n\n\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BED.Writer\n \n \nType\n.\n\n\nBED.Writer(output::IO)\n\n\n\n\n\nCreate a data writer of the BED file format.\n\n\nArguments:\n\n\n\n\noutput\n: data sink\n\n\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BED.Record\n \n \nType\n.\n\n\nBED.Record()\n\n\n\n\n\nCreate an unfilled BED record.\n\n\nsource\n\n\nBED.Record(data::Vector{UInt8})\n\n\n\n\n\nCreate a BED record object from \ndata\n.\n\n\nThis function verifies and indexes fields for accessors. Note that the ownership of \ndata\n is transferred to a new record object.\n\n\nsource\n\n\nBED.Record(str::AbstractString)\n\n\n\n\n\nCreate a BED record object from \nstr\n.\n\n\nThis function verifies and indexes fields for accessors.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BED.chrom\n \n \nFunction\n.\n\n\nchrom(record::Record)::String\n\n\n\n\n\nGet the chromosome name of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BED.chromstart\n \n \nFunction\n.\n\n\nchromstart(record::Record)::Int\n\n\n\n\n\nGet the starting position of \nrecord\n.\n\n\nNote that the first base is numbered 1.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BED.chromend\n \n \nFunction\n.\n\n\nchromend(record::Record)::Int\n\n\n\n\n\nGet the end position of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BED.name\n \n \nFunction\n.\n\n\nname(record::Record)::String\n\n\n\n\n\nGet the name of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BED.score\n \n \nFunction\n.\n\n\nscore(record::Record)::Int\n\n\n\n\n\nGet the score between 0 and 1000.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BED.strand\n \n \nFunction\n.\n\n\nstrand(record::Record)::GenomicFeatures.Strand\n\n\n\n\n\nGet the strand of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BED.thickstart\n \n \nFunction\n.\n\n\nthickstart(record::Record)::Int\n\n\n\n\n\nGet the starting position at which \nrecord\n is drawn thickly.\n\n\nNote that the first base is numbered 1.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BED.thickend\n \n \nFunction\n.\n\n\nthickend(record::Record)::Int\n\n\n\n\n\nGet the end position at which \nrecord\n is drawn thickly.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BED.itemrgb\n \n \nFunction\n.\n\n\nitemrgb(record::Record)::ColorTypes.RGB\n\n\n\n\n\nGet the RGB value of \nrecord\n.\n\n\nThe return type is defined in \nColorTypes.jl\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BED.blockcount\n \n \nFunction\n.\n\n\nblockcount(record::Record)::Int\n\n\n\n\n\nGet the number of blocks (exons) in \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BED.blocksizes\n \n \nFunction\n.\n\n\nblocksizes(record::Record)::Vector{Int}\n\n\n\n\n\nGet the block (exon) sizes of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BED.blockstarts\n \n \nFunction\n.\n\n\nblockstarts(record::Record)::Vector{Int}\n\n\n\n\n\nGet the block (exon) starts of \nrecord\n.\n\n\nNote that the first base is numbered 1.\n\n\nsource", 
            "title": "BED"
        }, 
        {
            "location": "/io/bed/#bed", 
            "text": "", 
            "title": "BED"
        }, 
        {
            "location": "/io/bed/#description", 
            "text": "BED is a text-based file format for representing genomic annotations like genes, transcripts, and so on. A BED file has tab-delimited and variable-length fields; the first three fields denoting a genomic interval are mandatory.  This is an example of RNA transcripts:  chr9    68331023    68424451    NM_015110   0   +\nchr9    68456943    68486659    NM_001206   0   -  I/O tools for BED are provided from the  GenomicFeatures.BED  module, which exports following three types:   Reader type:  BED.Reader  Writer type:  BED.Writer  Element type:  BED.Record", 
            "title": "Description"
        }, 
        {
            "location": "/io/bed/#examples", 
            "text": "Here is a common workflow to iterate over all records in a BED file:  # Import the BED module.  using   GenomicFeatures  # Open a BED file.  reader   =   open ( BED . Reader ,   data.bed )  # Iterate over records.  for   record   in   reader \n     # Do something on record (see Accessors section). \n     chrom   =   BED . chrom ( record ) \n     # ...  end  # Finally, close the reader.  close ( reader )   If you repeatedly access records within specific ranges, it would be more efficient to construct an  IntervalCollection  object from a BED reader:  # Create an interval collection in memory.  icol   =   open ( BED . Reader ,   data.bed )   do   reader \n     IntervalCollection ( reader )  end  # Query overlapping records.  for   interval   in   eachoverlap ( icol ,   Interval ( chrX ,   40001 ,   51500 )) \n     # A record is stored in the metadata field of an interval. \n     record   =   metadata ( interval ) \n     # ...  end", 
            "title": "Examples"
        }, 
        {
            "location": "/io/bed/#api", 
            "text": "#  GenomicFeatures.BED.Reader     Type .  BED . Reader ( input :: IO ;   index = nothing )  BED . Reader ( input :: AbstractString ;   index = : auto )   Create a data reader of the BED file format.  The first argument specifies the data source. When it is a filepath that ends with  .bgz , it is considered to be block compression file format (BGZF) and the function will try to find a tabix index file ( .tbi) and read it if any. See  http://www.htslib.org/doc/tabix.html  for bgzip and tabix tools.  Arguments   input : data source  index : path to a tabix file   source  #  GenomicFeatures.BED.Writer     Type .  BED.Writer(output::IO)  Create a data writer of the BED file format.  Arguments:   output : data sink   source  #  GenomicFeatures.BED.Record     Type .  BED.Record()  Create an unfilled BED record.  source  BED.Record(data::Vector{UInt8})  Create a BED record object from  data .  This function verifies and indexes fields for accessors. Note that the ownership of  data  is transferred to a new record object.  source  BED.Record(str::AbstractString)  Create a BED record object from  str .  This function verifies and indexes fields for accessors.  source  #  GenomicFeatures.BED.chrom     Function .  chrom(record::Record)::String  Get the chromosome name of  record .  source  #  GenomicFeatures.BED.chromstart     Function .  chromstart(record::Record)::Int  Get the starting position of  record .  Note that the first base is numbered 1.  source  #  GenomicFeatures.BED.chromend     Function .  chromend(record::Record)::Int  Get the end position of  record .  source  #  GenomicFeatures.BED.name     Function .  name(record::Record)::String  Get the name of  record .  source  #  GenomicFeatures.BED.score     Function .  score(record::Record)::Int  Get the score between 0 and 1000.  source  #  GenomicFeatures.BED.strand     Function .  strand(record::Record)::GenomicFeatures.Strand  Get the strand of  record .  source  #  GenomicFeatures.BED.thickstart     Function .  thickstart(record::Record)::Int  Get the starting position at which  record  is drawn thickly.  Note that the first base is numbered 1.  source  #  GenomicFeatures.BED.thickend     Function .  thickend(record::Record)::Int  Get the end position at which  record  is drawn thickly.  source  #  GenomicFeatures.BED.itemrgb     Function .  itemrgb(record::Record)::ColorTypes.RGB  Get the RGB value of  record .  The return type is defined in  ColorTypes.jl .  source  #  GenomicFeatures.BED.blockcount     Function .  blockcount(record::Record)::Int  Get the number of blocks (exons) in  record .  source  #  GenomicFeatures.BED.blocksizes     Function .  blocksizes(record::Record)::Vector{Int}  Get the block (exon) sizes of  record .  source  #  GenomicFeatures.BED.blockstarts     Function .  blockstarts(record::Record)::Vector{Int}  Get the block (exon) starts of  record .  Note that the first base is numbered 1.  source", 
            "title": "API"
        }, 
        {
            "location": "/io/gff3/", 
            "text": "GFF3\n\n\n\n\nDescription\n\n\nGFF3 is a text-based file format for representing genomic annotations. The major difference from BED is that GFF3 is more structured and can include sequences in the FASTA file format.\n\n\nI/O tools for GFF3 are provided from the \nGenomicFeatures.GFF3\n module, which exports following three types:\n\n\n\n\nReader type: \nGFF3.Reader\n\n\nWriter type: \nGFF3.Writer\n\n\nElement type: \nGFF3.Record\n\n\n\n\nA GFF3 file may contain directives and/or comments in addition to genomic features. These lines are skipped by default but you can control the behavior by passing keyword arguments to \nGFF3.Reader\n. See the docstring for details.\n\n\n\n\nExamples\n\n\nHere is a common workflow to iterate over all records in a GFF3 file:\n\n\n# Import the GFF3 module.\n\n\nusing\n \nGenomicFeatures\n\n\n\n# Open a GFF3 file.\n\n\nreader\n \n=\n \nopen\n(\nGFF3\n.\nReader\n,\n \ndata.gff3\n)\n\n\n\n# Iterate over records.\n\n\nfor\n \nrecord\n \nin\n \nreader\n\n    \n# Do something on record (see Accessors section).\n\n    \nseqid\n \n=\n \nGFF3\n.\nseqid\n(\nreader\n)\n\n    \n# ...\n\n\nend\n\n\n\n# Finally, close the reader\n\n\nclose\n(\nreader\n)\n\n\n\n\n\n\nIf you are interested in directives (which starts with '#') in addition to genomic features, you need to pass \nskip_directives=false\n when initializing a GFF3 constructor:\n\n\n# Set skip_directives to true (this is set to false by default).\n\n\nreader\n \n=\n \nGFF3\n.\nReader\n(\nopen\n(\ndata.gff3\n),\n \nskip_directives\n=\nfalse\n)\n\n\nfor\n \nrecord\n \nin\n \nrecord\n\n    \n# Branch by record type.\n\n    \nif\n \nGFF3\n.\nisfeature\n(\nrecord\n)\n\n        \n# ...\n\n    \nelseif\n \nGFF3\n.\nisdirective\n(\nrecord\n)\n\n        \n# ...\n\n    \nelse\n\n        \n# This never happens.\n\n        \nassert\n(\nfalse\n)\n\n    \nend\n\n\nend\n\n\nclose\n(\nreader\n)\n\n\n\n\n\n\nGenomicFeatures.jl supports \ntabix\n to retrieve records overlapping with a specific interval. First you need to create a block compression file from a GFF3 file using bgzip and then index it using tabix.\n\n\ncat data.gff3 | grep -v \n^#\n | sort -k1,1 -k4,4n | bgzip \ndata.gff3.bgz\ntabix data.gff3.bgz  # this creates data.gff3.bgz.tbi\n\n\n\n\n\nThen you can read the block compression file as follows:\n\n\n# Read the block compression gzip file.\n\n\nreader\n \n=\n \nGFF3\n.\nReader\n(\ndata.gff3.bgz\n)\n\n\nfor\n \nrecord\n \nin\n \neachoverlap\n(\nreader\n,\n \nInterval\n(\nchr1\n,\n \n250_000\n,\n \n300_000\n))\n\n    \n# Each record overlap the query interval.\n\n    \n# ...\n\n\nend\n\n\n\n\n\n\n\n\nAPI\n\n\n#\n\n\nGenomicFeatures.GFF3.Reader\n \n \nType\n.\n\n\nGFF3\n.\nReader\n(\ninput\n::\nIO\n;\n\n            \nindex\n=\nnothing\n,\n\n            \nsave_directives\n::\nBool\n=\nfalse\n,\n\n            \nskip_features\n::\nBool\n=\nfalse\n,\n\n            \nskip_directives\n::\nBool\n=\ntrue\n,\n\n            \nskip_comments\n::\nBool\n=\ntrue\n)\n\n\n\nGFF3\n.\nReader\n(\ninput\n::\nAbstractString\n;\n\n            \nindex\n=\n:\nauto\n,\n\n            \nsave_directives\n::\nBool\n=\nfalse\n,\n\n            \nskip_features\n::\nBool\n=\nfalse\n,\n\n            \nskip_directives\n::\nBool\n=\ntrue\n,\n\n            \nskip_comments\n::\nBool\n=\ntrue\n)\n\n\n\n\n\n\nCreate a reader for data in GFF3 format.\n\n\nThe first argument specifies the data source. When it is a filepath that ends with \n.bgz\n, it is considered to be block compression file format (BGZF) and the function will try to find a tabix index file (\n.tbi) and read it if any. See \nhttp://www.htslib.org/doc/tabix.html\n for bgzip and tabix tools.\n\n\nArguments\n\n\n\n\ninput\n: data source (\nIO\n object or filepath)\n\n\nindex\n: path to a tabix file\n\n\nsave_directives\n: flag to save directive records (which can be accessed with \nGFF3.directives\n)\n\n\nskip_features\n: flag to skip feature records\n\n\nskip_directives\n: flag to skip directive records\n\n\nskip_comments\n:  flag to skip comment records\n\n\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.GFF3.directives\n \n \nFunction\n.\n\n\nReturn all directives that preceded the last GFF entry parsed as an array of strings.\n\n\nDirectives at the end of the file can be accessed by calling \nclose(reader)\n and then \ndirectives(reader)\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.GFF3.hasfasta\n \n \nFunction\n.\n\n\nReturn true if the GFF3 stream is at its end and there is trailing FASTA data.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.GFF3.getfasta\n \n \nFunction\n.\n\n\nReturn a BioSequences.FASTA.Reader initialized to parse trailing FASTA data.\n\n\nThrows an exception if there is no trailing FASTA, which can be checked using \nhasfasta\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.GFF3.Writer\n \n \nType\n.\n\n\nGFF3.Writer(output::IO)\n\n\n\n\n\nCreate a data writer of the GFF3 file format.\n\n\nArguments:\n\n\n\n\noutput\n: data sink\n\n\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.GFF3.Record\n \n \nType\n.\n\n\nGFF3.Record()\n\n\n\n\n\nCreate an unfilled GFF3 record.\n\n\nsource\n\n\nGFF3.Record(data::Vector{UInt8})\n\n\n\n\n\nCreate a GFF3 record object from \ndata\n. This function verifies and indexes fields for accessors. Note that the ownership of \ndata\n is transferred to a new record object.\n\n\nsource\n\n\nGFF3.Record(str::AbstractString)\n\n\n\n\n\nCreate a GFF3 record object from \nstr\n. This function verifies and indexes fields for accessors.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.GFF3.isfeature\n \n \nFunction\n.\n\n\nisfeature(record::Record)::Bool\n\n\n\n\n\nTest if \nrecord\n is a feature record.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.GFF3.isdirective\n \n \nFunction\n.\n\n\nisdirective(record::Record)::Bool\n\n\n\n\n\nTest if \nrecord\n is a directive record.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.GFF3.iscomment\n \n \nFunction\n.\n\n\niscomment(record::Record)::Bool\n\n\n\n\n\nTest if \nrecord\n is a comment record.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.GFF3.seqid\n \n \nFunction\n.\n\n\nseqid(record::Record)::String\n\n\n\n\n\nGet the sequence ID of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.GFF3.source\n \n \nFunction\n.\n\n\nsource(record::Record)::String\n\n\n\n\n\nGet the source of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.GFF3.featuretype\n \n \nFunction\n.\n\n\nfeaturetype(record::Record)::String\n\n\n\n\n\nGet the type of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.GFF3.seqstart\n \n \nFunction\n.\n\n\nseqstart(record::Record)::Int\n\n\n\n\n\nGet the start coordinate of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.GFF3.seqend\n \n \nFunction\n.\n\n\nseqend(record::Record)::Int\n\n\n\n\n\nGet the end coordinate of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.GFF3.score\n \n \nFunction\n.\n\n\nscore(record::Record)::Float64\n\n\n\n\n\nGet the score of \nrecord\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.GFF3.strand\n \n \nFunction\n.\n\n\nstrand(record::Record)::GenomicFeatures.Strand\n\n\n\n\n\nGet the strand of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.GFF3.phase\n \n \nFunction\n.\n\n\nphase(record::Record)::Int\n\n\n\n\n\nGet the phase of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.GFF3.attributes\n \n \nFunction\n.\n\n\nattributes(record::Record)::Vector{Pair{String,Vector{String}}}\n\n\n\n\n\nGet the attributes of \nrecord\n.\n\n\nsource\n\n\nattributes(record::Record, key::String)::Vector{String}\n\n\n\n\n\nGet the attributes of \nrecord\n with \nkey\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.GFF3.content\n \n \nFunction\n.\n\n\ncontent(record::Record)::String\n\n\n\n\n\nGet the content of \nrecord\n. Leading '#' letters are removed.\n\n\nsource", 
            "title": "GFF3"
        }, 
        {
            "location": "/io/gff3/#gff3", 
            "text": "", 
            "title": "GFF3"
        }, 
        {
            "location": "/io/gff3/#description", 
            "text": "GFF3 is a text-based file format for representing genomic annotations. The major difference from BED is that GFF3 is more structured and can include sequences in the FASTA file format.  I/O tools for GFF3 are provided from the  GenomicFeatures.GFF3  module, which exports following three types:   Reader type:  GFF3.Reader  Writer type:  GFF3.Writer  Element type:  GFF3.Record   A GFF3 file may contain directives and/or comments in addition to genomic features. These lines are skipped by default but you can control the behavior by passing keyword arguments to  GFF3.Reader . See the docstring for details.", 
            "title": "Description"
        }, 
        {
            "location": "/io/gff3/#examples", 
            "text": "Here is a common workflow to iterate over all records in a GFF3 file:  # Import the GFF3 module.  using   GenomicFeatures  # Open a GFF3 file.  reader   =   open ( GFF3 . Reader ,   data.gff3 )  # Iterate over records.  for   record   in   reader \n     # Do something on record (see Accessors section). \n     seqid   =   GFF3 . seqid ( reader ) \n     # ...  end  # Finally, close the reader  close ( reader )   If you are interested in directives (which starts with '#') in addition to genomic features, you need to pass  skip_directives=false  when initializing a GFF3 constructor:  # Set skip_directives to true (this is set to false by default).  reader   =   GFF3 . Reader ( open ( data.gff3 ),   skip_directives = false )  for   record   in   record \n     # Branch by record type. \n     if   GFF3 . isfeature ( record ) \n         # ... \n     elseif   GFF3 . isdirective ( record ) \n         # ... \n     else \n         # This never happens. \n         assert ( false ) \n     end  end  close ( reader )   GenomicFeatures.jl supports  tabix  to retrieve records overlapping with a specific interval. First you need to create a block compression file from a GFF3 file using bgzip and then index it using tabix.  cat data.gff3 | grep -v  ^#  | sort -k1,1 -k4,4n | bgzip  data.gff3.bgz\ntabix data.gff3.bgz  # this creates data.gff3.bgz.tbi  Then you can read the block compression file as follows:  # Read the block compression gzip file.  reader   =   GFF3 . Reader ( data.gff3.bgz )  for   record   in   eachoverlap ( reader ,   Interval ( chr1 ,   250_000 ,   300_000 )) \n     # Each record overlap the query interval. \n     # ...  end", 
            "title": "Examples"
        }, 
        {
            "location": "/io/gff3/#api", 
            "text": "#  GenomicFeatures.GFF3.Reader     Type .  GFF3 . Reader ( input :: IO ; \n             index = nothing , \n             save_directives :: Bool = false , \n             skip_features :: Bool = false , \n             skip_directives :: Bool = true , \n             skip_comments :: Bool = true )  GFF3 . Reader ( input :: AbstractString ; \n             index = : auto , \n             save_directives :: Bool = false , \n             skip_features :: Bool = false , \n             skip_directives :: Bool = true , \n             skip_comments :: Bool = true )   Create a reader for data in GFF3 format.  The first argument specifies the data source. When it is a filepath that ends with  .bgz , it is considered to be block compression file format (BGZF) and the function will try to find a tabix index file ( .tbi) and read it if any. See  http://www.htslib.org/doc/tabix.html  for bgzip and tabix tools.  Arguments   input : data source ( IO  object or filepath)  index : path to a tabix file  save_directives : flag to save directive records (which can be accessed with  GFF3.directives )  skip_features : flag to skip feature records  skip_directives : flag to skip directive records  skip_comments :  flag to skip comment records   source  #  GenomicFeatures.GFF3.directives     Function .  Return all directives that preceded the last GFF entry parsed as an array of strings.  Directives at the end of the file can be accessed by calling  close(reader)  and then  directives(reader) .  source  #  GenomicFeatures.GFF3.hasfasta     Function .  Return true if the GFF3 stream is at its end and there is trailing FASTA data.  source  #  GenomicFeatures.GFF3.getfasta     Function .  Return a BioSequences.FASTA.Reader initialized to parse trailing FASTA data.  Throws an exception if there is no trailing FASTA, which can be checked using  hasfasta .  source  #  GenomicFeatures.GFF3.Writer     Type .  GFF3.Writer(output::IO)  Create a data writer of the GFF3 file format.  Arguments:   output : data sink   source  #  GenomicFeatures.GFF3.Record     Type .  GFF3.Record()  Create an unfilled GFF3 record.  source  GFF3.Record(data::Vector{UInt8})  Create a GFF3 record object from  data . This function verifies and indexes fields for accessors. Note that the ownership of  data  is transferred to a new record object.  source  GFF3.Record(str::AbstractString)  Create a GFF3 record object from  str . This function verifies and indexes fields for accessors.  source  #  GenomicFeatures.GFF3.isfeature     Function .  isfeature(record::Record)::Bool  Test if  record  is a feature record.  source  #  GenomicFeatures.GFF3.isdirective     Function .  isdirective(record::Record)::Bool  Test if  record  is a directive record.  source  #  GenomicFeatures.GFF3.iscomment     Function .  iscomment(record::Record)::Bool  Test if  record  is a comment record.  source  #  GenomicFeatures.GFF3.seqid     Function .  seqid(record::Record)::String  Get the sequence ID of  record .  source  #  GenomicFeatures.GFF3.source     Function .  source(record::Record)::String  Get the source of  record .  source  #  GenomicFeatures.GFF3.featuretype     Function .  featuretype(record::Record)::String  Get the type of  record .  source  #  GenomicFeatures.GFF3.seqstart     Function .  seqstart(record::Record)::Int  Get the start coordinate of  record .  source  #  GenomicFeatures.GFF3.seqend     Function .  seqend(record::Record)::Int  Get the end coordinate of  record .  source  #  GenomicFeatures.GFF3.score     Function .  score(record::Record)::Float64  Get the score of  record  source  #  GenomicFeatures.GFF3.strand     Function .  strand(record::Record)::GenomicFeatures.Strand  Get the strand of  record .  source  #  GenomicFeatures.GFF3.phase     Function .  phase(record::Record)::Int  Get the phase of  record .  source  #  GenomicFeatures.GFF3.attributes     Function .  attributes(record::Record)::Vector{Pair{String,Vector{String}}}  Get the attributes of  record .  source  attributes(record::Record, key::String)::Vector{String}  Get the attributes of  record  with  key .  source  #  GenomicFeatures.GFF3.content     Function .  content(record::Record)::String  Get the content of  record . Leading '#' letters are removed.  source", 
            "title": "API"
        }, 
        {
            "location": "/io/bigwig/", 
            "text": "bigWig\n\n\n\n\nDescription\n\n\nbigWig is a binary file format for associating a floating point number with each base in the genome. bigWig files are indexed to quickly fetch specific regions.\n\n\nI/O tools for bigWig are provided from the \nGenomicFeatures.BigWig\n module, which exports following three types:\n\n\n\n\nReader type: \nBigWig.Reader\n\n\nWriter type: \nBigWig.Writer\n\n\nElement type: \nBigWig.Record\n\n\n\n\n\n\nExamples\n\n\nA common workflow is to open a file, iterate over records, and close the file:\n\n\n# Import the BigWig module.\n\n\nusing\n \nGenomicFeatures\n\n\n\n# Open a bigWig file (e.g. mapping depth or coverage).\n\n\nreader\n \n=\n \nopen\n(\nBigWig\n.\nReader\n,\n \ndata.cov.bw\n)\n\n\n\n# Iterate over records overlapping with a query interval.\n\n\nfor\n \nrecord\n \nin\n \neachoverlap\n(\nreader\n,\n \nInterval\n(\nChr2\n,\n \n5001\n,\n \n6000\n))\n\n    \n# Extract the start position, end position and value of the record,\n\n    \nstartpos\n \n=\n \nBigWig\n.\nchromstart\n(\nrecord\n)\n\n    \nendpos\n \n=\n \nBigWig\n.\nchromend\n(\nrecord\n)\n\n    \nvalue\n \n=\n \nBigWig\n.\nvalue\n(\nrecord\n)\n\n    \n# and do something...\n\n\nend\n\n\n\n# Finally, close the reader.\n\n\nclose\n(\nreader\n)\n\n\n\n\n\n\nBigWig.values\n is a handy function that returns a vector of values. This returns a value per position within the query region:\n\n\n# Get values in Chr2:5001-6000 as a vector of 1000 elements.\n\n\nBigWig\n.\nvalues\n(\nreader\n,\n \nInterval\n(\nChr2\n,\n \n5001\n,\n \n6000\n))\n\n\n\n\n\n\nIterating over all records is also supported:\n\n\nreader\n \n=\n \nopen\n(\nBigWig\n.\nReader\n,\n \ndata.cov.bw\n)\n\n\nfor\n \nrecord\n \nin\n \nreader\n\n    \n# ...\n\n\nend\n\n\nclose\n(\nreader\n)\n\n\n\n\n\n\nCreating a bigWig can be written as follows:\n\n\n# Open an output file.\n\n\nfile\n \n=\n \nopen\n(\ndata.cov.bw\n,\n \nw\n)\n\n\n\n# Initialize a bigWig writer.\n\n\nwriter\n \n=\n \nBigWig\n.\nWriter\n(\nfile\n,\n \n[(\nchr1\n,\n \n2000\n),\n \n(\nchr2\n,\n \n1000\n)])\n\n\n\n# Write records.\n\n\nwrite\n(\nwriter\n,\n \n(\nchr1\n,\n   \n1\n,\n \n100\n,\n \n1.0\n))\n\n\nwrite\n(\nwriter\n,\n \n(\nchr1\n,\n \n101\n,\n \n200\n,\n \n2.1\n))\n\n\n# ...\n\n\nwrite\n(\nwriter\n,\n \n(\nchr2\n,\n  \n51\n,\n \n150\n,\n \n3.2\n))\n\n\n\n# Close the writer (this closes the file, too).\n\n\nclose\n(\nwriter\n)\n\n\n\n\n\n\n\n\nAPI\n\n\n#\n\n\nGenomicFeatures.BigWig.Reader\n \n \nType\n.\n\n\nBigWig.Reader(input::IO)\n\n\n\n\n\nCreate a reader for bigWig file format.\n\n\nNote that \ninput\n must be seekable.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigWig.chromlist\n \n \nFunction\n.\n\n\nchromlist(reader::BigWig.Reader)::Vector{Tuple{String,Int}}\n\n\n\n\n\nGet the \n(name, length)\n pairs of chromosomes/contigs.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigWig.values\n \n \nFunction\n.\n\n\nvalues(reader::BigWig.Reader, interval::Interval)::Vector{Float32}\n\n\n\n\n\nGet a vector of values within \ninterval\n from \nreader\n.\n\n\nThis function fills missing values with \nNaN32\n.\n\n\nsource\n\n\nvalues(reader::BigWig.Reader, chrom::AbstractString, range::UnitRange)::Vector{Float32}\n\n\n\n\n\nGet a vector of values within \nrange\n of \nchrom\n from \nreader\n.\n\n\nThis function fills missing values with \nNaN32\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigWig.Writer\n \n \nType\n.\n\n\nBigWig\n.\nWriter\n(\noutput\n::\nIO\n,\n \nchromlist\n;\n \nbinsize\n=\n64\n,\n \ndatatype\n=\n:\nbedgraph\n)\n\n\n\n\n\n\nCreate a data writer of the bigWig file format.\n\n\nArguments\n\n\n\n\noutput\n: data sink\n\n\nchromlist\n: chromosome list with length\n\n\nbinsize=64\n: size of a zoom with the highest resolution\n\n\ndatatype=:bedgraph\n: encoding of values (\n:bedgraph\n, \n:varstep\n or \n:fixedstep\n)\n\n\n\n\nExamples\n\n\noutput\n \n=\n \nopen\n(\ndata.bw\n,\n \nw\n)\n\n\nwriter\n \n=\n \nBigWig\n.\nWriter\n(\noutput\n,\n \n[(\nchr1\n,\n \n12345\n),\n \n(\nchr2\n,\n \n9100\n)])\n\n\nwrite\n(\nwriter\n,\n \n(\nchr1\n,\n \n501\n,\n \n600\n,\n \n1.0\n))\n\n\nwrite\n(\nwriter\n,\n \n(\nchr2\n,\n \n301\n,\n \n450\n,\n \n3.0\n))\n\n\nclose\n(\nwriter\n)\n\n\n\n\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigWig.Record\n \n \nType\n.\n\n\nBigWig.Record()\n\n\n\n\n\nCreate an unfilled bigWig record.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigWig.chrom\n \n \nFunction\n.\n\n\nchrom(record::Record)::String\n\n\n\n\n\nGet the chromosome name of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigWig.chromid\n \n \nFunction\n.\n\n\nchromid(record::Record)::UInt32\n\n\n\n\n\nGet the chromosome ID of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigWig.chromstart\n \n \nFunction\n.\n\n\nchromstart(record::Record)::Int\n\n\n\n\n\nGet the start position of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigWig.chromend\n \n \nFunction\n.\n\n\nchromend(record::Record)::Int\n\n\n\n\n\nGet the end position of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigWig.value\n \n \nFunction\n.\n\n\nvalue(record::Record)::Float32\n\n\n\n\n\nGet the value of \nrecord\n.\n\n\nsource", 
            "title": "BigWig"
        }, 
        {
            "location": "/io/bigwig/#bigwig", 
            "text": "", 
            "title": "bigWig"
        }, 
        {
            "location": "/io/bigwig/#description", 
            "text": "bigWig is a binary file format for associating a floating point number with each base in the genome. bigWig files are indexed to quickly fetch specific regions.  I/O tools for bigWig are provided from the  GenomicFeatures.BigWig  module, which exports following three types:   Reader type:  BigWig.Reader  Writer type:  BigWig.Writer  Element type:  BigWig.Record", 
            "title": "Description"
        }, 
        {
            "location": "/io/bigwig/#examples", 
            "text": "A common workflow is to open a file, iterate over records, and close the file:  # Import the BigWig module.  using   GenomicFeatures  # Open a bigWig file (e.g. mapping depth or coverage).  reader   =   open ( BigWig . Reader ,   data.cov.bw )  # Iterate over records overlapping with a query interval.  for   record   in   eachoverlap ( reader ,   Interval ( Chr2 ,   5001 ,   6000 )) \n     # Extract the start position, end position and value of the record, \n     startpos   =   BigWig . chromstart ( record ) \n     endpos   =   BigWig . chromend ( record ) \n     value   =   BigWig . value ( record ) \n     # and do something...  end  # Finally, close the reader.  close ( reader )   BigWig.values  is a handy function that returns a vector of values. This returns a value per position within the query region:  # Get values in Chr2:5001-6000 as a vector of 1000 elements.  BigWig . values ( reader ,   Interval ( Chr2 ,   5001 ,   6000 ))   Iterating over all records is also supported:  reader   =   open ( BigWig . Reader ,   data.cov.bw )  for   record   in   reader \n     # ...  end  close ( reader )   Creating a bigWig can be written as follows:  # Open an output file.  file   =   open ( data.cov.bw ,   w )  # Initialize a bigWig writer.  writer   =   BigWig . Writer ( file ,   [( chr1 ,   2000 ),   ( chr2 ,   1000 )])  # Write records.  write ( writer ,   ( chr1 ,     1 ,   100 ,   1.0 ))  write ( writer ,   ( chr1 ,   101 ,   200 ,   2.1 ))  # ...  write ( writer ,   ( chr2 ,    51 ,   150 ,   3.2 ))  # Close the writer (this closes the file, too).  close ( writer )", 
            "title": "Examples"
        }, 
        {
            "location": "/io/bigwig/#api", 
            "text": "#  GenomicFeatures.BigWig.Reader     Type .  BigWig.Reader(input::IO)  Create a reader for bigWig file format.  Note that  input  must be seekable.  source  #  GenomicFeatures.BigWig.chromlist     Function .  chromlist(reader::BigWig.Reader)::Vector{Tuple{String,Int}}  Get the  (name, length)  pairs of chromosomes/contigs.  source  #  GenomicFeatures.BigWig.values     Function .  values(reader::BigWig.Reader, interval::Interval)::Vector{Float32}  Get a vector of values within  interval  from  reader .  This function fills missing values with  NaN32 .  source  values(reader::BigWig.Reader, chrom::AbstractString, range::UnitRange)::Vector{Float32}  Get a vector of values within  range  of  chrom  from  reader .  This function fills missing values with  NaN32 .  source  #  GenomicFeatures.BigWig.Writer     Type .  BigWig . Writer ( output :: IO ,   chromlist ;   binsize = 64 ,   datatype = : bedgraph )   Create a data writer of the bigWig file format.  Arguments   output : data sink  chromlist : chromosome list with length  binsize=64 : size of a zoom with the highest resolution  datatype=:bedgraph : encoding of values ( :bedgraph ,  :varstep  or  :fixedstep )   Examples  output   =   open ( data.bw ,   w )  writer   =   BigWig . Writer ( output ,   [( chr1 ,   12345 ),   ( chr2 ,   9100 )])  write ( writer ,   ( chr1 ,   501 ,   600 ,   1.0 ))  write ( writer ,   ( chr2 ,   301 ,   450 ,   3.0 ))  close ( writer )   source  #  GenomicFeatures.BigWig.Record     Type .  BigWig.Record()  Create an unfilled bigWig record.  source  #  GenomicFeatures.BigWig.chrom     Function .  chrom(record::Record)::String  Get the chromosome name of  record .  source  #  GenomicFeatures.BigWig.chromid     Function .  chromid(record::Record)::UInt32  Get the chromosome ID of  record .  source  #  GenomicFeatures.BigWig.chromstart     Function .  chromstart(record::Record)::Int  Get the start position of  record .  source  #  GenomicFeatures.BigWig.chromend     Function .  chromend(record::Record)::Int  Get the end position of  record .  source  #  GenomicFeatures.BigWig.value     Function .  value(record::Record)::Float32  Get the value of  record .  source", 
            "title": "API"
        }, 
        {
            "location": "/io/bigbed/", 
            "text": "bigBed\n\n\nDescription \u2013\u2013\u2013\u2013\u2013-\n\n\nbigBed is a binary file format for representing genomic annotations and often created from BED files. bigBed files are indexed to quickly fetch specific regions.\n\n\nI/O tools for bigBed are provided from the \nGenomicFeatures.BigBed\n module, which exports following three types:\n\n\n\n\nReader type: \nBigBed.Reader\n\n\nWritre type: \nBigBed.Writer\n\n\nElement type: \nBigBed.Record\n\n\n\n\n\n\nExamples\n\n\nA common workflow is to open a file, iterate over records, and close the file:\n\n\n# Import the BigBed module.\n\n\nusing\n \nGenomicFeatures\n\n\n\n# Open a bigBed file.\n\n\nreader\n \n=\n \nopen\n(\nBigBed\n.\nReader\n,\n \ndata.bb\n)\n\n\n\n# Iterate over records overlapping with a query interval.\n\n\nfor\n \nrecord\n \nin\n \neachoverlap\n(\nreader\n,\n \nInterval\n(\nChr2\n,\n \n5001\n,\n \n6000\n))\n\n    \n# Extract the start position, end position and value of the record,\n\n    \nstartpos\n \n=\n \nBigBed\n.\nchromstart\n(\nrecord\n)\n\n    \nendpos\n \n=\n \nBigBed\n.\nchromend\n(\nrecord\n)\n\n    \nvalue\n \n=\n \nBigBed\n.\nvalue\n(\nrecord\n)\n\n    \n# and do something...\n\n\nend\n\n\n\n# Finally, close the reader.\n\n\nclose\n(\nreader\n)\n\n\n\n\n\n\nIterating over all records is also supported:\n\n\nreader\n \n=\n \nopen\n(\nBigBed\n.\nReader\n,\n \ndata.bb\n)\n\n\nfor\n \nrecord\n \nin\n \nreader\n\n    \n# ...\n\n\nend\n\n\nclose\n(\nreader\n)\n\n\n\n\n\n\nCreating a bigBed file can be done as follows. The \nwrite\n call takes a tuple of 3-12 elements (i.e. chromosome name, start position, end position, name, score, strand, thickstart, thickend, RGB color, blockcount, blocksizes and blockstarts). The first three are mandatory fields but others are optional.\n\n\n# Import RGB type.\n\n\nusing\n \nColorTypes\n\n\nfile\n \n=\n \nopen\n(\ndata.bb\n,\n \nw\n)\n\n\nwriter\n \n=\n \nBigBed\n.\nWriter\n(\nfile\n,\n \n[(\nchr1\n,\n \n1000\n)])\n\n\nwrite\n(\nwriter\n,\n \n(\nchr1\n,\n \n1\n,\n \n100\n,\n \nsome name\n,\n \n100\n,\n \n+\n,\n \n10\n,\n \n90\n,\n \nRGB\n(\n0.5\n,\n \n0.1\n,\n \n0.2\n),\n \n2\n,\n \n[\n4\n,\n \n10\n],\n \n[\n10\n,\n \n20\n]))\n\n\nclose\n(\nwriter\n)\n\n\n\n\n\n\n\n\nAPI\n\n\n#\n\n\nGenomicFeatures.BigBed.Reader\n \n \nType\n.\n\n\nBigBed.Reader(input::IO)\n\n\n\n\n\nCreate a reader for bigBed file format.\n\n\nNote that \ninput\n must be seekable.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigBed.chromlist\n \n \nFunction\n.\n\n\nchromlist(reader::BigBed.Reader)::Vector{Tuple{String,Int}}\n\n\n\n\n\nGet the \n(name, length)\n pairs of chromosomes/contigs.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigBed.Writer\n \n \nType\n.\n\n\nBigBed\n.\nWriter\n(\noutput\n::\nIO\n,\n \nchromlist\n;\n \nbinsize\n=\n64\n)\n\n\n\n\n\n\nCreate a data writer of the bigBed file format.\n\n\nArguments\n\n\n\n\noutput\n: data sink\n\n\nchromlist\n: chromosome list with length\n\n\nbinsize=64\n: size of a zoom with the highest resolution\n\n\n\n\nExamples\n\n\noutput\n \n=\n \nopen\n(\ndata.bb\n,\n \nw\n)\n\n\nwriter\n \n=\n \nBigBed\n.\nWriter\n(\noutput\n,\n \n[(\nchr1\n,\n \n12345\n),\n \n(\nchr2\n,\n \n9100\n)])\n\n\nwrite\n(\nwriter\n,\n \n(\nchr1\n,\n \n101\n,\n \n150\n,\n \ngene 1\n))\n\n\nwrite\n(\nwriter\n,\n \n(\nchr2\n,\n \n211\n,\n \n250\n,\n \ngene 2\n))\n\n\nclose\n(\nwriter\n)\n\n\n\n\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigBed.Record\n \n \nType\n.\n\n\nBigBed.Record()\n\n\n\n\n\nCreate an unfilled bigBed record.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigBed.chrom\n \n \nFunction\n.\n\n\nchrom(record::Record)::String\n\n\n\n\n\nGet the chromosome name of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigBed.chromid\n \n \nFunction\n.\n\n\nchromid(record::Record)::UInt32\n\n\n\n\n\nGet the chromosome ID of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigBed.chromstart\n \n \nFunction\n.\n\n\nchromstart(record::Record)::Int\n\n\n\n\n\nGet the start position of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigBed.chromend\n \n \nFunction\n.\n\n\nchromend(record::Record)::Int\n\n\n\n\n\nGet the end position of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigBed.name\n \n \nFunction\n.\n\n\nname(record::Record)::String\n\n\n\n\n\nGet the name of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigBed.score\n \n \nFunction\n.\n\n\nscore(record::Record)::Int\n\n\n\n\n\nGet the score between 0 and 1000.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigBed.strand\n \n \nFunction\n.\n\n\nstrand(record::Record)::GenomicFeatures.Strand\n\n\n\n\n\nGet the strand of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigBed.thickstart\n \n \nFunction\n.\n\n\nthickstart(record::Record)::Int\n\n\n\n\n\nGet the starting position at which \nrecord\n is drawn thickly.\n\n\nNote that the first base is numbered 1.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigBed.thickend\n \n \nFunction\n.\n\n\nthickend(record::Record)::Int\n\n\n\n\n\nGet the end position at which \nrecord\n is drawn thickly.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigBed.itemrgb\n \n \nFunction\n.\n\n\nitemrgb(record::Record)::ColorTypes.RGB\n\n\n\n\n\nGet the RGB value of \nrecord\n.\n\n\nThe return type is defined in \nColorTypes.jl\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigBed.blockcount\n \n \nFunction\n.\n\n\nblockcount(record::Record)::Int\n\n\n\n\n\nGet the number of blocks (exons) in \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigBed.blocksizes\n \n \nFunction\n.\n\n\nblocksizes(record::Record)::Vector{Int}\n\n\n\n\n\nGet the block (exon) sizes of \nrecord\n.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigBed.blockstarts\n \n \nFunction\n.\n\n\nblockstarts(record::Record)::Vector{Int}\n\n\n\n\n\nGet the block (exon) starts of \nrecord\n.\n\n\nNote that the first base is numbered 1.\n\n\nsource\n\n\n#\n\n\nGenomicFeatures.BigBed.optionals\n \n \nFunction\n.\n\n\noptionals(record::Record)::Vector{String}\n\n\n\n\n\nGet optional fields as strings.\n\n\nsource", 
            "title": "BigBed"
        }, 
        {
            "location": "/io/bigbed/#bigbed", 
            "text": "Description \u2013\u2013\u2013\u2013\u2013-  bigBed is a binary file format for representing genomic annotations and often created from BED files. bigBed files are indexed to quickly fetch specific regions.  I/O tools for bigBed are provided from the  GenomicFeatures.BigBed  module, which exports following three types:   Reader type:  BigBed.Reader  Writre type:  BigBed.Writer  Element type:  BigBed.Record", 
            "title": "bigBed"
        }, 
        {
            "location": "/io/bigbed/#examples", 
            "text": "A common workflow is to open a file, iterate over records, and close the file:  # Import the BigBed module.  using   GenomicFeatures  # Open a bigBed file.  reader   =   open ( BigBed . Reader ,   data.bb )  # Iterate over records overlapping with a query interval.  for   record   in   eachoverlap ( reader ,   Interval ( Chr2 ,   5001 ,   6000 )) \n     # Extract the start position, end position and value of the record, \n     startpos   =   BigBed . chromstart ( record ) \n     endpos   =   BigBed . chromend ( record ) \n     value   =   BigBed . value ( record ) \n     # and do something...  end  # Finally, close the reader.  close ( reader )   Iterating over all records is also supported:  reader   =   open ( BigBed . Reader ,   data.bb )  for   record   in   reader \n     # ...  end  close ( reader )   Creating a bigBed file can be done as follows. The  write  call takes a tuple of 3-12 elements (i.e. chromosome name, start position, end position, name, score, strand, thickstart, thickend, RGB color, blockcount, blocksizes and blockstarts). The first three are mandatory fields but others are optional.  # Import RGB type.  using   ColorTypes  file   =   open ( data.bb ,   w )  writer   =   BigBed . Writer ( file ,   [( chr1 ,   1000 )])  write ( writer ,   ( chr1 ,   1 ,   100 ,   some name ,   100 ,   + ,   10 ,   90 ,   RGB ( 0.5 ,   0.1 ,   0.2 ),   2 ,   [ 4 ,   10 ],   [ 10 ,   20 ]))  close ( writer )", 
            "title": "Examples"
        }, 
        {
            "location": "/io/bigbed/#api", 
            "text": "#  GenomicFeatures.BigBed.Reader     Type .  BigBed.Reader(input::IO)  Create a reader for bigBed file format.  Note that  input  must be seekable.  source  #  GenomicFeatures.BigBed.chromlist     Function .  chromlist(reader::BigBed.Reader)::Vector{Tuple{String,Int}}  Get the  (name, length)  pairs of chromosomes/contigs.  source  #  GenomicFeatures.BigBed.Writer     Type .  BigBed . Writer ( output :: IO ,   chromlist ;   binsize = 64 )   Create a data writer of the bigBed file format.  Arguments   output : data sink  chromlist : chromosome list with length  binsize=64 : size of a zoom with the highest resolution   Examples  output   =   open ( data.bb ,   w )  writer   =   BigBed . Writer ( output ,   [( chr1 ,   12345 ),   ( chr2 ,   9100 )])  write ( writer ,   ( chr1 ,   101 ,   150 ,   gene 1 ))  write ( writer ,   ( chr2 ,   211 ,   250 ,   gene 2 ))  close ( writer )   source  #  GenomicFeatures.BigBed.Record     Type .  BigBed.Record()  Create an unfilled bigBed record.  source  #  GenomicFeatures.BigBed.chrom     Function .  chrom(record::Record)::String  Get the chromosome name of  record .  source  #  GenomicFeatures.BigBed.chromid     Function .  chromid(record::Record)::UInt32  Get the chromosome ID of  record .  source  #  GenomicFeatures.BigBed.chromstart     Function .  chromstart(record::Record)::Int  Get the start position of  record .  source  #  GenomicFeatures.BigBed.chromend     Function .  chromend(record::Record)::Int  Get the end position of  record .  source  #  GenomicFeatures.BigBed.name     Function .  name(record::Record)::String  Get the name of  record .  source  #  GenomicFeatures.BigBed.score     Function .  score(record::Record)::Int  Get the score between 0 and 1000.  source  #  GenomicFeatures.BigBed.strand     Function .  strand(record::Record)::GenomicFeatures.Strand  Get the strand of  record .  source  #  GenomicFeatures.BigBed.thickstart     Function .  thickstart(record::Record)::Int  Get the starting position at which  record  is drawn thickly.  Note that the first base is numbered 1.  source  #  GenomicFeatures.BigBed.thickend     Function .  thickend(record::Record)::Int  Get the end position at which  record  is drawn thickly.  source  #  GenomicFeatures.BigBed.itemrgb     Function .  itemrgb(record::Record)::ColorTypes.RGB  Get the RGB value of  record .  The return type is defined in  ColorTypes.jl .  source  #  GenomicFeatures.BigBed.blockcount     Function .  blockcount(record::Record)::Int  Get the number of blocks (exons) in  record .  source  #  GenomicFeatures.BigBed.blocksizes     Function .  blocksizes(record::Record)::Vector{Int}  Get the block (exon) sizes of  record .  source  #  GenomicFeatures.BigBed.blockstarts     Function .  blockstarts(record::Record)::Vector{Int}  Get the block (exon) starts of  record .  Note that the first base is numbered 1.  source  #  GenomicFeatures.BigBed.optionals     Function .  optionals(record::Record)::Vector{String}  Get optional fields as strings.  source", 
            "title": "API"
        }
    ]
}